<!-- hide -->
# Tutorial del proyecto Clasificador de Im√°genes
<!-- endhide -->

- Escribir√°s un algoritmo para clasificar si las im√°genes contienen un perro o un gato. Esto es f√°cil para humanos, perros y gatos. Tu computadora lo encontrar√° un poco m√°s dif√≠cil.

> ¬°No te olvides de ser siempre ingenioso!

## üå±  C√≥mo iniciar este proyecto

Esta vez no se har√° Fork, t√≥mate un tiempo para leer estas instrucciones:

1. Crear un nuevo repositorio basado en el [proyecto de Machine Learing](https://github.com/4GeeksAcademy/machine-learning-python-template/generate) [haciendo clic aqu√≠](https://github.com/4GeeksAcademy/machine-learning-python-template).
2. Abre el repositorio creado recientemente en Gitpod usando la [extensi√≥n del bot√≥n de Gitpod](https://www.gitpod.io/docs/browser-extension/).
3. Una vez que Gitpod VSCode haya terminado de abrirse, comienza tu proyecto siguiendo las instrucciones a continuaci√≥n.

## üöõ C√≥mo entregar este proyecto

Una vez que hayas terminado de resolver los ejercicios, aseg√∫rate de confirmar tus cambios, hazle "push" a el fork de tu repositorio y ve a 4Geeks.com para subir el enlace del repositorio.

## üìù Instructions

**Clasificador de im√°genes**

El conjunto de datos se compone de fotos de perros y gatos proporcionadas como un subconjunto de fotos de un conjunto de datos mucho m√°s grande de 3 millones de fotos anotadas manualmente. El conjunto de datos se desarroll√≥ como una asociaci√≥n entre Petfinder.com y Microsoft.

El conjunto de datos se us√≥ originalmente como un CAPTCHA, es decir, una tarea que se cree que un humano encuentra trivial, pero que una m√°quina no puede resolver, que se usa en sitios web para distinguir entre usuarios humanos y bots. La tarea se denomin√≥ "Asirra". Cuando se present√≥ "Asirra", se mencion√≥ "que los estudios de usuarios indican que los humanos pueden resolverlo el 99,6% de las veces en menos de 30 segundos". A menos que se produzca un gran avance en la visi√≥n artificial, esperamos que los ordenadores no tengan m√°s de 1/54.000 posibilidades de resolverlo.

En el momento en que se public√≥ la competencia, el resultado de √∫ltima generaci√≥n se logr√≥ con un SVM y se describi√≥ en un art√≠culo de 2007 con el t√≠tulo "Ataques de Machine Learning contra el CAPTCHA de Asirra" (PDF) que logr√≥ una precisi√≥n de clasificaci√≥n del 80 %. Fue este documento el que demostr√≥ que la tarea ya no era una tarea adecuada para un CAPTCHA poco despu√©s de que se propusiera la tarea.

El conjunto de datos es f√°cil de entender y lo suficientemente peque√±o como para caber en la memoria y comenzar con la visi√≥n artificial y las redes neuronales convolucionales.

Enlaces de conjuntos de datos:

https://www.kaggle.com/c/dogs-vs-cats/data

**Paso 1:**

Descarga la carpeta datatset y descomprime los archivos. Ahora tendr√°s una carpeta llamada 'tren/' que contiene 25 000 archivos .jpg de perros y gatos. Las fotos est√°n etiquetadas por su nombre de archivo, con la palabra ‚Äúperro‚Äù o ‚Äúgato‚Äù.

**Paso 2:**

Importa las siguientes bibliotecas:

```py
import keras,os
from keras.models import Sequential  #ya que todas las capas del modelo se organizar√°n en secuencia
from keras.layers import Dense, Conv2D, MaxPool2D , Flatten
from keras.preprocessing.image import ImageDataGenerator #ya que importa datos con etiquetas f√°cilmente al modelo. Tiene funciones para cambiar la escala, rotar, hacer zoom, etc. Esta clase altera los datos sobre la marcha mientras los pasa al modelo.
import numpy as np
```

**Paso 3:**

Carga y traza las primeras nueve fotos de perros en una sola figura. Repite lo mismo para los gatos. Puedes ver que las fotos son a color y tienen diferentes formas y tama√±os.

Las fotos deber√°n remodelarse antes del modelado para que todas las im√°genes tengan la misma forma. Esto es a menudo una peque√±a imagen cuadrada. Las entradas m√°s peque√±as significan un modelo que es m√°s r√°pido de entrenar, por lo que elegiremos un tama√±o fijo de 200 √ó 200 p√≠xeles.

Podr√≠amos cargar todas las im√°genes, remodelarlas y almacenarlas como un solo array NumPy. Esto podr√≠a caber en la memoria RAM en muchas m√°quinas modernas, pero no en todas, especialmente si solo tienes 8 gigabytes para trabajar.

Podemos escribir c√≥digo personalizado para cargar las im√°genes en la memoria y cambiarles el tama√±o como parte del proceso de carga, luego guardarlas listas para el modelado.

1. Si tienes m√°s de 12 gigabytes de RAM, use la API de procesamiento de im√°genes de Keras para cargar las 25¬†000 fotos en el conjunto de datos de entrenamiento y remodelarlas a fotos cuadradas de 200 √ó 200. La etiqueta tambi√©n debe determinarse para cada foto en funci√≥n de los nombres de archivo. Se debe guardar una tupla de fotos y etiquetas.

2. Si no tienes m√°s de 12 gigabytes de RAM, carga las im√°genes progresivamente usando la clase Keras ImageDataGenerator y la API flow_from_directory(). Esto ser√° m√°s lento de ejecutar pero se ejecutar√° en m√°s m√°quinas. Esta API prefiere que los datos se dividan en directorios train/ y test/ separados, y debajo de cada directorio para tener un subdirectorio para cada clase.

**Paso 4:**

Create an object of ImageDataGenerator for both training and testing data and pass the folder which has train data to the object trdata and similarly pass the folder which has test data to the object tsdata. 

The ImageDataGenerator will automatically label all the data inside cat folder as cat and vis-√†-vis for dog folder. In this way data is easily ready to be passed to the neural network.

**Paso 5:**

Cualquier clasificador que se ajuste a este problema tendr√° que ser robusto porque algunas im√°genes muestran al gato o al perro en una esquina o tal vez a 2 gatos o perros en la misma foto. VGG16 es una arquitectura de red neuronal de convoluci√≥n (CNN) utilizada para ganar la competencia ILSVR (Imagenet) en 2014. Se considera una de las arquitecturas de modelos de visi√≥n excelentes hasta la fecha.

Lo m√°s singular de VGG16 es que, en lugar de tener una gran cantidad de hiperpar√°metros, se enfocaron en tener capas de convoluci√≥n de filtro 3x3 con un paso 1 y siempre usaron el mismo relleno y la misma capa maxpool de filtro 2x2 de paso 2. Sigue esto disposici√≥n de las capas de convoluci√≥n y maxpool consistentemente a lo largo de toda la arquitectura. Al final, tiene 2 FC (capas totalmente conectadas) seguidas de un softmax para la salida. El 16 en VGG16 se refiere a que tiene 16 capas que tienen pesos. Esta red es bastante grande y tiene alrededor de 138 millones (aprox.) de par√°metros.

Inicializa el modelo especificando que el modelo es un modelo secuencial. Despu√©s de inicializar el modelo, agrega:

‚Üí 2 x capa de convoluci√≥n de 64 canales de 3x3 kernel y mismo relleno.

‚Üí 1 x capa maxpool de tama√±o piscina 2x2 y zancada 2x2.

‚Üí 2 x capa de convoluci√≥n de 128 canales de 3x3 kernel y mismo relleno.

‚Üí 1 x capa maxpool de tama√±o piscina 2x2 y zancada 2x2.

‚Üí 3 x capa de convoluci√≥n de 256 canales de 3x3 kernel y mismo relleno.

‚Üí 1 x capa maxpool de tama√±o piscina 2x2 y zancada 2x2.

‚Üí 3 x capa de convoluci√≥n de 512 canales de 3x3 kernel y mismo relleno.

‚Üí 1 x capa maxpool de tama√±o piscina 2x2 y zancada 2x2.

‚Üí 3 x capa de convoluci√≥n de 512 canales de 3x3 kernel y mismo relleno.

‚Üí 1 x capa maxpool de tama√±o piscina 2x2 y zancada 2x2.

Agrega la activaci√≥n de relu (Unidad lineal rectificada) a cada capa para que todos los valores negativos no pasen a la siguiente capa.

Veamos unas primeras filas para tener una idea, y seguir con todas las capas:

```py
model = Sequential()
model.add(Conv2D(input_shape=(224,224,3),filters=64,kernel_size=(3,3),padding="same", activation="relu"))
model.add(Conv2D(filters=64,kernel_size=(3,3),padding="same", activation="relu"))
model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))
model.add(Conv2D(filters=128, kernel_size=(3,3), padding="same", activation="relu"))
```

**Paso 6:**

Despu√©s de crear toda la convoluci√≥n, pasa los datos a la capa densa. Para hacer eso, primero debes aplanar el vector que sale de las circunvoluciones y luego agregar:

‚Üí 1 x Capa densa de 4096 unidades

‚Üí 1 x Capa densa de 4096 unidades

‚Üí 1 x Capa Dense Softmax de 2 unidades

Usa la activaci√≥n RELU para ambas capas densas para dejar de reenviar valores negativos a trav√©s de la red. Use una capa densa de 2 unidades al final con activaci√≥n softmax ya que tiene 2 clases para predecir. La capa softmax generar√° el valor entre 0 y 1 en funci√≥n de la confianza del modelo en la clase a la que pertenecen las im√°genes.

**Paso 7:**

Importa el optimizador de Adam y util√≠zalo para compilar el modelo. Especifica una tasa de aprendizaje para ello.

**Paso 8:**

Consulta el resumen del modelo

**Paso 9:**

Importa el m√©todo ModelCheckpoint y EarlyStopping de keras. Crea un objeto de ambos y p√°selo como funciones de devoluci√≥n de llamada a fit_generator.

**Paso 10:**

Una vez que hayas entrenado el modelo, visualiza la precisi√≥n y la p√©rdida del entrenamiento/validaci√≥n.

**Paso 11:**

Carga el mejor modelo guardado y preprocesa la imagen, luego pasa la imagen al modelo y haz predicciones.

**Paso 12:**

Usa tu archivo app.py para crear su clasificador de im√°genes.

En tu archivo README escribe un breve resumen.

Gu√≠a de soluciones: 

https://github.com/4GeeksAcademy/image-classifier-project-tutorial/blob/main/solution_guide.ipynb
